{"cells":[{"cell_type":"markdown","source":["imports"],"metadata":{"id":"NkM7UdYYmCZF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FErX9P2UwzrT"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","%cd '/content/drive/My Drive/Colab Notebooks'\n","\n","!pip install import-ipynb\n","\n","import import_ipynb\n","\n","from bce_loss_functions import *\n","\n","from cce_loss_functions import *\n","\n","from custom_metrics import *\n","\n","from custom_data_loader import custom_image_dataset_from_directory\n","\n","from fairface_data_loader import column_clean_up, get_labels\n","\n","import pandas as pd\n","\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from keras import layers\n","\n","from keras.models import Model"]},{"cell_type":"markdown","source":["constants and variables"],"metadata":{"id":"CvmJmtjfmHPz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TP0ZtWYGxRjg"},"outputs":[],"source":["FILEPATHS = {\n","\n","\n","            'TRAIN_LABELS':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/data/fairface/split/train/train_labels_dir_ordered.csv',\n","            'TEST_LABELS':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/data/fairface/split/test/test_labels_dir_ordered.csv',\n","            'VAL_LABELS':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/data/fairface/split/validation/validation_labels_dir_ordered.csv',\n","\n","}\n","\n","DIRECTORIES = {\n","\n","            'MODELS':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/models/fairface/',\n","            'MODEL_CP':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/models/fairface.mcp/',\n","            'OUTPUT':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/output/fairface/',\n","\n","            'TRAIN_IMGS':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/data/fairface/train/',\n","            'VAL_IMGS':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/data/fairface/validation/',\n","            'TEST_IMGS':'/content/drive/MyDrive/Colab Notebooks/s2_dissertation/data/fairface/test/',\n","\n","}\n","\n","\n","CATEGORIES = ['race','race-sex']\n","\n","TARGETS = ['adult','race', 'race-sex','sex']\n","\n","NUMBER_OF_CLASSES = {'adult':1,'race':7,'race-sex':14,'sex':1}\n","\n","VERBOSE = 1\n","\n","category = 'race-sex'\n","\n","target = 'sex'\n","\n","binary = True if target == 'adult' or target == 'sex' else False\n"]},{"cell_type":"markdown","source":["data and preprocessing functions"],"metadata":{"id":"bxQHICIIoeNk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SGmOBKBbjTC"},"outputs":[],"source":["from keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n","\n","h_flip =  keras.layers.RandomFlip(mode='horizontal', seed=1127)\n","\n","rotate = keras.layers.RandomRotation(0.2, seed=8675)\n","\n","def preprocess(images, labels=None):\n","\n","  return preprocess_input(images), labels\n","\n","def preprocess_training(images, labels=None):\n","\n","  images = preprocess_input(images)\n","\n","  images = rotate(images,training=True)\n","\n","  images = h_flip(images,training=True)\n","\n","  return images, labels\n","\n","def get_dataset(data_type='TRAIN',shuffle=True):\n","\n","    print('category:\\t{}\\ntarget:\\t{}\\ndata: {}'.format(category,target,data_type))\n","\n","    key = '{}_LABELS'.format(data_type)\n","\n","    df = pd.read_csv(FILEPATHS[key])\n","\n","    df, category_names = column_clean_up(df)\n","\n","    key = '{}_IMGS'.format(data_type)\n","\n","    labels = get_labels(df,category=category,target=target,number_of_classes=NUMBER_OF_CLASSES[target],c_names=category_names[category],verbose=False)\n","\n","    dataset, _ = custom_image_dataset_from_directory(\n","            DIRECTORIES[key],\n","            labels=labels,\n","            color_mode='rgb',\n","            batch_size=32,\n","            image_size=(200, 200),\n","            shuffle=shuffle,\n","            interpolation='bilinear'\n","        )\n","\n","    dataset = dataset.map(preprocess_training) if data_type == 'TRAIN' else dataset.map(preprocess)\n","\n","    return dataset"]},{"cell_type":"markdown","source":["get data"],"metadata":{"id":"j5zf-gxdpSQF"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209321,"status":"ok","timestamp":1719646391300,"user":{"displayName":"Christina","userId":"00461187038940699873"},"user_tz":300},"id":"PoM_3sXpxC5m","outputId":"3e0622db-86e9-4f45-b76f-d646b5496b76"},"outputs":[{"name":"stdout","output_type":"stream","text":["category:\trace-sex\n","target:\tsex\n","data: TRAIN\n","Found 69396 files\n","category:\trace-sex\n","target:\tsex\n","data: TEST\n","Found 17348 files\n","category:\trace-sex\n","target:\tsex\n","data: VAL\n","Found 10954 files\n"]}],"source":["train_data = get_dataset(data_type='TRAIN',shuffle=True)\n","\n","test_data = get_dataset(data_type='TEST',shuffle=False)\n","\n","val_data = get_dataset(data_type='VAL',shuffle=False)"]},{"cell_type":"markdown","source":["function for model creation, training, and initial evaluation"],"metadata":{"id":"vY_gLE-KpZ-K"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"grkMFGON33qR"},"outputs":[],"source":["def create_model(model_name=None,loss=None):\n","\n","    binary = True if target == 'sex' else False\n","\n","    inputs = keras.Input(shape=(200,200,3))\n","\n","    base_model = ResNet50V2(\n","        include_top=False,\n","        input_shape=(200, 200, 3),\n","        input_tensor=inputs,\n","        weights='imagenet',\n","    )\n","\n","    base_model.trainable = False  # freeze all base model (ResNet50V2) layers to preserve the imagenet weights for transfer learning\n","\n","    # unfreeze only the batch normalization layers so they can learn the new data's batch means and variances\n","\n","    for layer in base_model.layers:\n","\n","        if 'BatchNormalization' in layer.__class__.__name__:\n","\n","            layer.trainable = True\n","\n","    x = base_model.output\n","\n","    x = layers.GlobalAveragePooling2D()(x) # add trainable global average pooling layer to model\n","\n","    x = layers.Dropout(0.7)(x) # add dropout to model\n","\n","    output = layers.Dense(1, activation='sigmoid')(x) if binary else layers.Dense(7, activation='softmax')(x) # add final layer for either binary or categorical classification\n","\n","    model = Model(inputs = base_model.input, outputs = output)\n","\n","    model.summary(show_trainable=True)\n","\n","    metrics = [CBA(),CTP(),CFP(),CTN(),CFN()] if binary else [CCA(number_of_classes=NUMBER_OF_CLASSES[target])] # custom metrics\n","\n","    callbacks = [\n","                keras.callbacks.ReduceLROnPlateau(\n","                    monitor='val_loss',\n","                    factor=0.1,\n","                    patience=5,\n","                    verbose=1,\n","                    mode='auto',\n","                    min_delta=1e-4,\n","                    cooldown=0,\n","                    min_lr=0\n","                ),\n","                keras.callbacks.ModelCheckpoint(\n","                    DIRECTORIES['MODEL_CP'] + '{}_'.format(model_name) + '{epoch:02d}-{val_loss:.2f}.keras',\n","                    monitor='val_{}'.format(metrics[0].name), # monitor validation accuracy since loss will be impacted negatively due to modified loss function\n","                    verbose=1,\n","                    save_best_only=True,\n","                    save_weights_only=False,\n","                    mode='auto',\n","                    save_freq='epoch',\n","                    initial_value_threshold=None\n","                )\n","    ]\n","\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001,weight_decay=None), loss=loss, metrics=metrics)\n","\n","    history = model.fit(train_data, validation_data=val_data, epochs=15, verbose=VERBOSE, callbacks=callbacks)\n","\n","    base_model.trainable = True  # unfreeze all base model (ResNet50V2) layers for fine tuning the model\n","\n","    model_path = DIRECTORIES['MODEL_CP'] + model_name + '_1.keras'\n","\n","    model.save(model_path)\n","\n","    print('acc:\\t',history.history[metrics[0].name][-1])\n","\n","    print('loss:\\t',history.history['loss'][-1])\n","\n","    if binary:\n","\n","        print('tp:\\t',history.history['custom_true_positives'][-1])\n","\n","        print('fp:\\t',history.history['custom_false_positives'][-1])\n","\n","        print('tn:\\t',history.history['custom_true_negatives'][-1])\n","\n","        print('fn:\\t',history.history['custom_false_negatives'][-1])\n","\n","    model.compile(optimizer=keras.optimizers.Adam(0.0001,weight_decay=0.0),loss=loss,metrics=metrics) # reduce learning rate for fine tuning\n","\n","    history = model.fit(train_data, validation_data=val_data, epochs=15, verbose=VERBOSE, callbacks=callbacks)\n","\n","    model_path = DIRECTORIES['MODELS'] + model_name + '_2.keras'\n","\n","    model.save(model_path)\n","\n","    print('acc:\\t',history.history[metrics[0].name][-1])\n","\n","    print('loss:\\t',history.history['loss'][-1])\n","\n","    if binary:\n","\n","        print('tp:\\t',history.history['custom_true_positives'][-1])\n","\n","        print('fp:\\t',history.history['custom_false_positives'][-1])\n","\n","        print('tn:\\t',history.history['custom_true_negatives'][-1])\n","\n","        print('fn:\\t',history.history['custom_false_negatives'][-1])\n","\n","    # evaluate the model on validation and test data, then log results\n","\n","    val_results = model.evaluate(val_data)\n","\n","    print(val_results)\n","\n","    test_results = model.evaluate(test_data)\n","\n","    print(test_results)\n","\n","    fn = DIRECTORIES['OUTPUT'] + 'fairface_dir_model_metrics_t-{}_c-{}.csv'.format(target,category)\n","\n","    f = open(fn, 'a')\n","\n","    if binary:\n","\n","        f.write('{},{},{},{},{},{},{},{},{},{},{},{},{}\\n'.format(model_name,val_results[0],val_results[1],val_results[2],val_results[3],val_results[4],val_results[5],test_results[0],test_results[1],test_results[2],test_results[3],test_results[4],test_results[5]))\n","\n","    else:\n","\n","        f.write('{},{},{},{},{}\\n'.format(model_name,val_results[0],val_results[1],test_results[0],test_results[1]))\n","\n","    f.close()\n","\n"]},{"cell_type":"markdown","source":["create and train single group risk modified loss models"],"metadata":{"id":"rf059MGYvOv3"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d2gK_8BLxLRj"},"outputs":[],"source":["print('category:\\t{}\\ntarget:\\t{}'.format(category,target))\n","\n","fn = DIRECTORIES['OUTPUT'] + 'fairface_dir_model_metrics_t-{}_c-{}.csv'.format(target,category)\n","\n","f = open(fn, 'w')\n","\n","if binary:\n","\n","    f.write('model,val_loss,val_acc,val_tp,val_fp,val_tn,val_fn,test_loss,test_acc,test_tp,test_fp,test_tn,test_fn\\n')\n","\n","else:\n","\n","    f.write('model,val_loss,val_acc,test_loss,test_acc\\n')\n","\n","f.close()\n","\n","for alpha in [0,0.5,0.9]:\n","\n","    print('\\n\\nalpha value:\\t\\t',alpha)\n","\n","    losses = None\n","\n","    if binary:\n","\n","        losses = {\n","            'v1:MGR_Equity_BCE':MaxGroupRiskBCEv1(alpha=alpha),\n","            'v2:MGR_Equality_BCE':MaxGroupRiskBCEv2(alpha=alpha),\n","            'v1:ASD_Equity_BCE':AbSumDiffBCEv1(alpha=alpha),\n","            'v2:ASD_Equality_BCE':AbSumDiffBCEv2(alpha=alpha),\n","        }\n","\n","    else:\n","\n","        losses = {\n","            'v1:MGR_Equity_CCE':MaxGroupRiskCCEv1(alpha=alpha,number_of_classes=NUMBER_OF_CLASSES[target]),\n","            'v1:ASD_Equity_CCE':AbSumDiffCCEv1(alpha=alpha,number_of_classes=NUMBER_OF_CLASSES[target])\n","        }\n","\n","\n","    for ver,loss in losses.items():\n","\n","        model_name = '{}_{}_'.format(ver,alpha)\n","\n","        print('\\n\\ncreating {} alpha = {} loss function model'.format(ver,alpha))\n","\n","        create_model(model_name + 'fairface_dir_c-{}_t-{}'.format(category,target),loss)"]},{"cell_type":"markdown","source":["create and train combo group risk modified loss models"],"metadata":{"id":"rr0LkSbqwSJQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nMY82KWcLZW2"},"outputs":[],"source":["print('category:\\t{}\\ntarget:\\t{}'.format(category,target))\n","\n","for alpha in [0.5,0.9]:\n","\n","    for beta in [0.25,0.5,0.75]:\n","\n","        print('\\n\\nalpha-beta value:\\t\\t{} - {}',alpha,beta)\n","\n","        losses = None\n","\n","        if binary:\n","\n","            losses = {\n","                'v3:MGR_Equity_BCE':MaxGroupRiskBCEv3(alpha=alpha,beta=beta),\n","                'v3:ASD_Equity_BCE':AbSumDiffBCEv3(alpha=alpha,beta=beta),\n","                'v4:MGR_ASD_BCE':MaxAbSumDiffBCEv1(alpha=alpha,beta=beta),\n","                'v5:MGR_ASD_BCE':MaxAbSumDiffBCEv2(alpha=alpha,beta=beta),\n","                'v6:MGR_ASD_BCE':MaxAbSumDiffBCEv3(alpha=alpha,beta=beta),\n","                'v7:MGR_ASD_BCE':MaxAbSumDiffBCEv4(alpha=alpha,beta=beta)\n","            }\n","\n","        else:\n","\n","            losses = {\n","                'v4:MGR_ASD_CCE':MaxAbSumDiffCCEv1(alpha=alpha,beta=beta,number_of_classes=NUMBER_OF_CLASSES[target]),\n","            }\n","\n","        for ver,loss in losses.items():\n","\n","            model_name = '{}_{}_{}_'.format(ver,alpha,beta)\n","\n","            print('\\n\\ncreating {} alpha = {} beta = {} loss function model'.format(ver,alpha,beta))\n","\n","            create_model(model_name + 'fairface_dir_c-{}_t-{}'.format(category,target),loss)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"17C8kaR81f-_yO4rdrdR7Pbav2YdbUMU1","timestamp":1719032285539},{"file_id":"1OU1PKiJF4YFV2mdKdmbWniINSIPE5Z-U","timestamp":1718934492579}],"authorship_tag":"ABX9TyOVHDSyMN2thiGIUY4jgaf8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}