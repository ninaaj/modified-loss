{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZ27zDpfxO9duGrKTo/IJV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This code is a slightly altered version of tf.keras.preprocessing code\n","\n","original source: https://github.com/keras-team/keras/blob/v3.3.3/keras/src/utils/image_dataset_utils.py#L12-L351"],"metadata":{"id":"6EF0TYKycopl"}},{"cell_type":"markdown","source":["imports"],"metadata":{"id":"JJDKQwTpZoa5"}},{"cell_type":"code","source":["\n","import os\n","import random\n","import time\n","import warnings\n","from multiprocessing.pool import ThreadPool\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from keras.src.utils import dataset_utils\n","from keras.src.utils import image_utils\n","from keras.src.utils import io_utils\n","\n"],"metadata":{"id":"q0yLF8EFUAAu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["constants and variables"],"metadata":{"id":"6yvDPO6QZz1h"}},{"cell_type":"code","source":["ALLOWLIST_FORMATS = ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"],"metadata":{"id":"i5xNwUx_Zxh7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["data functions"],"metadata":{"id":"Aw5uH6Pmbd7O"}},{"cell_type":"code","source":["def standardize_data_format(data_format):\n","\n","    if data_format is None:\n","\n","        return 'channels_last'\n","\n","    return data_format\n","\n","def labels_to_dataset(labels):\n","\n","    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n","\n","    return label_ds\n","\n","def iter_valid_files(directory, follow_links, formats):\n","\n","    if not follow_links:\n","\n","        walk = tf.io.gfile.walk(directory)\n","\n","    else:\n","\n","        walk = os.walk(directory, followlinks=follow_links)\n","\n","    for root, _, files in sorted(walk, key=lambda x: x[0]):\n","\n","        for fname in sorted(files):\n","\n","            if fname.lower().endswith(formats):\n","\n","                yield root, fname\n","\n","def index_subdirectory(directory, class_indices, follow_links, formats):\n","\n","    dirname = os.path.basename(directory)\n","    valid_files = iter_valid_files(directory, follow_links, formats)\n","    labels = []\n","    filenames = []\n","    for root, fname in valid_files:\n","        labels.append(class_indices[dirname])\n","        absolute_path = tf.io.gfile.join(root, fname)\n","        relative_path = tf.io.gfile.join(\n","            dirname, os.path.relpath(absolute_path, directory)\n","        )\n","        filenames.append(relative_path)\n","    return filenames, labels\n","\n","def index_directory(\n","    directory,\n","    labels,\n","    formats,\n","    class_names=None,\n","    shuffle=True,\n","    seed=None,\n","    follow_links=False,\n","    verbose=True,\n","):\n","\n","    subdirs = ['']\n","\n","    class_names = subdirs\n","\n","    class_indices = dict(zip(class_names, range(len(class_names))))\n","\n","    pool = ThreadPool()\n","    results = []\n","    filenames = []\n","\n","    for dirpath in (tf.io.gfile.join(directory, subdir) for subdir in subdirs):\n","        results.append(\n","            pool.apply_async(\n","                index_subdirectory,\n","                (dirpath, class_indices, follow_links, formats),\n","            )\n","        )\n","    labels_list = []\n","    for res in results:\n","        partial_filenames, partial_labels = res.get()\n","        labels_list.append(partial_labels)\n","        filenames += partial_filenames\n","\n","    if verbose:\n","        io_utils.print_msg(f'Found {len(filenames)} files.')\n","\n","    pool.close()\n","    pool.join()\n","    file_paths = [tf.io.gfile.join(directory, fname) for fname in filenames]\n","\n","    if shuffle:\n","        # Shuffle globally to erase macro-structure\n","        if seed is None:\n","            seed = np.random.randint(1e6)\n","        rng = np.random.RandomState(seed)\n","        rng.shuffle(file_paths)\n","        if labels is not None:\n","            rng = np.random.RandomState(seed)\n","            rng.shuffle(labels)\n","    return file_paths, labels, class_names\n","\n","def custom_image_dataset_from_directory(\n","    directory,\n","    labels=[],\n","    class_names=None,\n","    color_mode='rgb',\n","    batch_size=32,\n","    image_size=(200, 200),\n","    shuffle=False,\n","    seed=None,\n","    validation_split=None,\n","    subset=None,\n","    interpolation='bilinear',\n","    follow_links=False,\n","    crop_to_aspect_ratio=False,\n","    pad_to_aspect_ratio=False,\n","    data_format=None,\n","    verbose=True,\n","):\n","    if color_mode == 'rgb':\n","        num_channels = 3\n","    elif color_mode == 'rgba':\n","        num_channels = 4\n","    elif color_mode == 'grayscale':\n","        num_channels = 1\n","    else:\n","        raise ValueError(\n","            '`color_mode` must be one of {\"rgb\", \"rgba\", \"grayscale\"}. '\n","            f'Received: color_mode={color_mode}'\n","        )\n","\n","    interpolation = interpolation.lower()\n","    supported_interpolations = (\n","        'bilinear',\n","        'nearest',\n","        'bicubic',\n","        'area',\n","        'lanczos3',\n","        'lanczos5',\n","        'gaussian',\n","        'mitchellcubic',\n","    )\n","    if interpolation not in supported_interpolations:\n","        raise ValueError(\n","            'Argument `interpolation` should be one of '\n","            f'{supported_interpolations}. '\n","            f'Received: interpolation={interpolation}'\n","        )\n","\n","    if seed is None:\n","        seed = np.random.randint(1e6)\n","\n","    image_paths, labels, class_names = index_directory(\n","        directory,\n","        labels,\n","        formats=ALLOWLIST_FORMATS,\n","        class_names=class_names,\n","        shuffle=shuffle,\n","        seed=seed,\n","        follow_links=follow_links,\n","        verbose=verbose,\n","    )\n","\n","    data_format = standardize_data_format(data_format=data_format)\n","    if batch_size is not None:\n","        shuffle_buffer_size = batch_size * 8\n","    else:\n","        shuffle_buffer_size = 1024\n","\n","    if not image_paths:\n","            raise ValueError(\n","                f'No images found in directory {directory}. '\n","                f'Allowed formats: {ALLOWLIST_FORMATS}'\n","            )\n","\n","    dataset = paths_and_labels_to_dataset(\n","            image_paths=image_paths,\n","            image_size=image_size,\n","            num_channels=num_channels,\n","            labels=labels,\n","            interpolation=interpolation,\n","            crop_to_aspect_ratio=crop_to_aspect_ratio,\n","            pad_to_aspect_ratio=pad_to_aspect_ratio,\n","            data_format=data_format,\n","            shuffle=shuffle,\n","            shuffle_buffer_size=shuffle_buffer_size,\n","            seed=seed,\n","    )\n","\n","    if batch_size is not None:\n","        dataset = dataset.batch(batch_size)\n","\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","        # Users may need to reference `class_names`.\n","    dataset.class_names = class_names\n","\n","        # Include file paths for images as attribute.\n","    dataset.file_paths = image_paths\n","\n","    return dataset, image_paths\n","\n","def paths_and_labels_to_dataset(\n","    image_paths,\n","    image_size,\n","    num_channels,\n","    labels,\n","    interpolation,\n","    data_format,\n","    crop_to_aspect_ratio=False,\n","    pad_to_aspect_ratio=False,\n","    shuffle=False,\n","    shuffle_buffer_size=None,\n","    seed=None,\n","):\n","    '''Constructs a dataset of images and labels.'''\n","    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n","\n","    label_ds = labels_to_dataset(labels)\n","\n","    ds = tf.data.Dataset.zip((path_ds, label_ds))\n","\n","    if shuffle:\n","        ds = ds.shuffle(buffer_size=shuffle_buffer_size or 1024, seed=seed)\n","\n","    args = (\n","        image_size,\n","        num_channels,\n","        interpolation,\n","        data_format,\n","        crop_to_aspect_ratio,\n","        pad_to_aspect_ratio,\n","    )\n","    ds = ds.map(\n","            lambda x, y: (load_image(x, *args), y),\n","            num_parallel_calls=tf.data.AUTOTUNE,\n","        )\n","\n","    return ds\n","\n","def load_image(\n","    path,\n","    image_size,\n","    num_channels,\n","    interpolation,\n","    data_format,\n","    crop_to_aspect_ratio=False,\n","    pad_to_aspect_ratio=False,\n","):\n","    '''Load an image from a path and resize it.'''\n","    img = tf.io.read_file(path)\n","    img = tf.image.decode_image(\n","        img, channels=num_channels, expand_animations=False\n","    )\n","\n","    if pad_to_aspect_ratio and crop_to_aspect_ratio:\n","        raise ValueError(\n","            'Only one of `pad_to_aspect_ratio`, `crop_to_aspect_ratio`'\n","            ' can be set to `True`.'\n","        )\n","\n","    if crop_to_aspect_ratio:\n","        from keras.src.backend import tensorflow as tf_backend\n","\n","        if data_format == 'channels_first':\n","            img = tf.transpose(img, (2, 0, 1))\n","        img = image_utils.smart_resize(\n","            img,\n","            image_size,\n","            interpolation=interpolation,\n","            data_format=data_format,\n","            backend_module=tf_backend,\n","        )\n","    elif pad_to_aspect_ratio:\n","        img = tf.image.resize_with_pad(\n","            img, image_size[0], image_size[1], method=interpolation\n","        )\n","        if data_format == 'channels_first':\n","            img = tf.transpose(img, (2, 0, 1))\n","    else:\n","        img = tf.image.resize(img, image_size, method=interpolation)\n","        if data_format == 'channels_first':\n","            img = tf.transpose(img, (2, 0, 1))\n","\n","    if data_format == 'channels_last':\n","        img.set_shape((image_size[0], image_size[1], num_channels))\n","    else:\n","        img.set_shape((num_channels, image_size[0], image_size[1]))\n","    return img"],"metadata":{"id":"DNFd_F-SXLmr"},"execution_count":null,"outputs":[]}]}