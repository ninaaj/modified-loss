{"cells":[{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"pYVWaLCejqf5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxaWk6EqVMDf"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","%cd '/content/drive/My Drive/Colab Notebooks'\n","\n","!pip install import-ipynb\n","\n","import import_ipynb\n","\n","from hmda_data_loader import *\n","\n","import pandas as pd\n","\n","import numpy as np\n","\n","import random as rd\n","\n","import tensorflow as tf\n","\n","from tensorflow.python.framework import constant_op\n","\n","from tensorflow import keras\n","\n","from keras import layers\n","\n","from scipy.stats import chi2_contingency"]},{"cell_type":"markdown","source":["Constants and variables"],"metadata":{"id":"0mNLE8_VjveF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fi_sLqVRV0ru"},"outputs":[],"source":["DIRECTORIES = {\n","    'MODELS':'/content/drive/MyDrive/Colab Notebooks/models/hmda/',\n","    'OUTPUT':'/content/drive/MyDrive/Colab Notebooks/ouput/hmda/'\n","}"]},{"cell_type":"markdown","source":["Get data"],"metadata":{"id":"F-PpF0TBkI2F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKPUjsRS_4kZ"},"outputs":[],"source":["category = 'race'\n","\n","print('\\nloading training data\\n')\n","\n","train_X,train_Y,train_ = get_data(dataset_type='train',category=category,normalization='std')\n","\n","train_data = tf.convert_to_tensor(train_X,dtype='float32')\n","train_targets = tf.convert_to_tensor(train_[1],dtype='float32')\n","\n","train_Xc = train_[0]\n","\n","cat_names = train_[3]\n","\n","train_data_c = tf.convert_to_tensor(train_Xc,dtype='float32')\n","\n","print('train accept:\\t\\t',int(np.sum(train_[1])))\n","print('train denied:\\t\\t',len(train_[1]) - int(np.sum(train_[1])))\n","print('train accept rate:\\t',np.sum(train_[1])/len(train_[1]))\n","\n","print(train_data.shape)\n","print(train_targets.shape)\n","print(train_data_c.shape)\n","\n","print('\\nloading test data\\n')\n","\n","test_X,test_Y,test_ = get_data(dataset_type='test',category=category,sample=False,sample_method='random',normalization='std')\n","\n","test_data = tf.convert_to_tensor(test_X,dtype='float32')\n","\n","test_targets = tf.convert_to_tensor(test_[1],dtype='float32')\n","\n","test_Xc = test_[0]\n","\n","test_cats = test_[2]\n","\n","test_data_c = tf.convert_to_tensor(test_Xc,dtype='float32')\n","\n","print('test accept:\\t\\t',int(np.sum(test_[1])))\n","print('test denied:\\t\\t',len(test_[1]) - int(np.sum(test_[1])))\n","print('test accept rate:\\t',np.sum(test_[1])/len(test_[1]))\n","\n","print(test_data.shape)\n","print(test_targets.shape)\n","print(test_data_c.shape)"]},{"cell_type":"markdown","source":["Create and train models"],"metadata":{"id":"wYFUsBUOkMeI"}},{"cell_type":"code","source":["callbacks = [tf.keras.callbacks.EarlyStopping(\n","                monitor='val_loss',\n","                min_delta=1e-4,\n","                patience=3,\n","                verbose=0,\n","                mode='auto',\n","                baseline=None,\n","                restore_best_weights=True,\n","                start_from_epoch=0,)]\n","\n","num_epochs = 15\n","\n","batch_size = 128\n","\n","steps_per_epoch = ((len(train_data) * 0.8) // batch_size) + 1\n","\n","activation = 'sigmoid'\n","\n","learning_rate = 0.01\n","\n","verbose = 1\n","\n","model_path = DIRECTORIES['MODELS'] + 'standard_hdma_ca_22_bce_{}_b.keras'.format(category)\n","\n","model = keras.Sequential([layers.Dense(1, activation=activation)])\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(name='true_positives'),tf.keras.metrics.TrueNegatives(name='true_negatives'),tf.keras.metrics.FalsePositives(name='false_positives'),tf.keras.metrics.FalseNegatives(name='false_negatives')])\n","\n","history = model.fit(train_data, train_targets, validation_split=0.2, shuffle=True, epochs=num_epochs, batch_size=batch_size,  steps_per_epoch=steps_per_epoch, verbose=verbose, callbacks=callbacks)\n","\n","print('acc:\\t',history.history['binary_accuracy'][-1])\n","print('loss:\\t',history.history['loss'][-1])\n","\n","print('tp history:\\t',history.history['true_positives'][-1])\n","print('tn history:\\t',history.history['true_negatives'][-1])\n","print('fp history:\\t',history.history['false_positives'][-1])\n","print('fn history:\\t',history.history['false_negatives'][-1])\n","\n","model.save(model_path)\n","\n","model_path = DIRECTORIES['MODELS'] + 'standard_hdma_ca_22_bce_{}_c.keras'.format(category)\n","\n","model = keras.Sequential([layers.Dense(1, activation=activation)])\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.TruePositives(name='true_positives'),tf.keras.metrics.TrueNegatives(name='true_negatives'),tf.keras.metrics.FalsePositives(name='false_positives'),tf.keras.metrics.FalseNegatives(name='false_negatives')])\n","\n","history = model.fit(train_data_c, train_targets, validation_split=0.2, shuffle=True, epochs=num_epochs, batch_size=batch_size,  steps_per_epoch=steps_per_epoch, verbose=verbose, callbacks=callbacks)\n","\n","print('acc:\\t',history.history['binary_accuracy'][-1])\n","print('loss:\\t',history.history['loss'][-1])\n","\n","print('tp history:\\t',history.history['true_positives'][-1])\n","print('tn history:\\t',history.history['true_negatives'][-1])\n","print('fp history:\\t',history.history['false_positives'][-1])\n","print('fn history:\\t',history.history['false_negatives'][-1])\n","\n","model.save(model_path)\n"],"metadata":{"id":"YkrrStHaGe3B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test and evaluate models"],"metadata":{"id":"qMES_H3ZkSwY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IKII3jpmN4cZ"},"outputs":[],"source":["def metrics(y_true,y_pred,data_type,category,write=False,writer=None):\n","\n","    mets = {\n","        'bac':tf.keras.metrics.BinaryAccuracy(),\n","        'bce':tf.keras.losses.BinaryCrossentropy(),\n","        'tp':tf.keras.metrics.TruePositives(),\n","        'tn':tf.keras.metrics.TrueNegatives(),\n","        'fp':tf.keras.metrics.FalsePositives(),\n","        'fn':tf.keras.metrics.FalseNegatives()\n","    }\n","\n","    for n,m in mets.items():\n","\n","        if n == 'bce':\n","            continue\n","\n","        m.update_state(y_true,y_pred)\n","\n","    tar = (mets['tp'].result().numpy() + mets['fn'].result().numpy()) / y_true.shape[0]\n","\n","    par = (mets['tp'].result().numpy() + mets['fp'].result().numpy()) / y_true.shape[0]\n","\n","    if write:\n","\n","        writer.write('{},{},{},{},{},{},{},{},{},{}\\n'.format(\n","                                                                   data_type,\n","                                                                   category,\n","\n","                                                                   mets['bac'].result().numpy(),\n","\n","                                                                   mets['bce'](y_true,y_pred).numpy(),\n","                                                                   par,\n","                                                                    tar,\n","                                                                   int(mets['tp'].result().numpy()),\n","                                                                   int(mets['tn'].result().numpy()),\n","                                                                   int(mets['fp'].result().numpy()),\n","                                                                   int(mets['fn'].result().numpy())))\n","\n","\n","\n","    return tar,par\n","\n","def test_model(model,data,targets,targets_c,cats,data_type,category,write=False,writer=None):\n","\n","\n","    cat_y_trues = {1:[],2:[]} if category == 'sex' else {1:[],2:[],3:[],4:[],5:[]} if category == 'race' else {11:[],12:[],21:[],22:[],31:[],32:[],41:[],42:[],51:[],52:[]}\n","\n","    cat_y_preds = {1:[],2:[]} if category == 'sex' else {1:[],2:[],3:[],4:[],5:[]} if category == 'race' else {11:[],12:[],21:[],22:[],31:[],32:[],41:[],42:[],51:[],52:[]}\n","\n","    y_pred = model.predict(data)\n","\n","    metrics(targets,tf.convert_to_tensor(y_pred),data_type,category,write,writer)\n","\n","    yl = list(y_pred)\n","\n","    for i in range(len(cats)):\n","\n","        cat_y_trues[cats[i]].append(targets_c[i])\n","\n","        cat_y_preds[cats[i]].append(yl[i])\n","\n","    for k,v in cat_names.items():\n","\n","        metrics(tf.convert_to_tensor(cat_y_trues[k]),tf.convert_to_tensor(cat_y_preds[k]),data_type,v,write,writer)\n","\n","    y_predl = [1 if y > 0.5 else 0 for y in list(y_pred)]\n","\n","    y_preds = pd.Series(y_predl,name='predictions')\n","\n","    catss = pd.Series(cats,name='categories')\n","\n","    contigency = pd.crosstab(index=catss, columns=y_preds)\n","\n","    print('\\n\\n',contigency)\n","\n","    contigency_pct = pd.crosstab(catss, y_preds, normalize='index')\n","\n","    print('\\n',contigency_pct)\n","\n","    c, p, dof, expected = chi2_contingency(contigency,correction=False)\n","\n","    return p\n","\n","def evaluate_model(model_path,data_type,category,eval_data,eval_targets,targets_c,eval_cats,batch_size=128,writer=None):\n","\n","    model = tf.keras.models.load_model(model_path)\n","\n","    results = model.evaluate(eval_data,eval_targets,batch_size=128)\n","\n","    print('eval loss, eval acc:', results)\n","\n","    return test_model(model,eval_data,eval_targets,targets_c,eval_cats,data_type,category,True,writer)\n","\n","\n"]},{"cell_type":"code","source":["model_paths = {'base': DIRECTORIES['MODELS'] + 'standard_hdma_ca_22_bce_{}_b.keras',\n","            'category': DIRECTORIES['MODELS'] + 'standard_hdma_ca_22_bce_{}_c.keras'}\n","\n","fn = DIRECTORIES['OUTPUT']  + 'standard_hmda_ca_22_{}_p_values.csv'.format(category)\n","\n","f = open(fn, 'w')\n","\n","f.write('model,category,p-value\\n')\n","\n","fn2 = DIRECTORIES['OUTPUT'] + 'standard_hmda_ca_22_{}_data.csv'.format(category)\n","\n","f2 = open(fn2, 'w')\n","\n","f2.write('data_type,category,bin_accuracy,bce_loss,par,tar,true_positives,true_negatives,false_positives,false_negatives\\n')\n","\n","p_value = evaluate_model(model_paths['base'].format(category),'base_features','all',test_data,test_targets,test_[1],test_cats,writer=f2)\n","\n","f.write('{},{},{}\\n'.format('base',category,p_value))\n","\n","p_value = evaluate_model(model_paths['category'].format(category),'category_features','all',test_data_c,test_targets,test_[1],test_cats,writer=f2)\n","\n","f.write('{},{},{}\\n'.format('category','all',p_value))\n","\n","f.close()\n","\n","f2.close()"],"metadata":{"id":"nOXAWNxHC6Tn"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"16Q49HEEaBCBr55XOFWwJUOHnA40yQ820","timestamp":1703744661851},{"file_id":"1gbv9ZYxExlOl4rOxH8qjDIfQjjrDySTs","timestamp":1702935723405},{"file_id":"1TbcjttS1El64fMNsaT3tVRKGlj9RO-ti","timestamp":1702782197350},{"file_id":"14QwCxHmARhwW8SeJELYFIQbDke_CCUr4","timestamp":1702703056082},{"file_id":"1rVyNlDR-JNP_7Aq3JGVk-VlQt_-cxvas","timestamp":1691655571367},{"file_id":"1fbPdSYHB2IfZrAdPgs6hjMEnQVwvSeGi","timestamp":1690238607139},{"file_id":"1geHmMM8002PCEWL9Thkn9nyoDXeAbQmw","timestamp":1689662795592},{"file_id":"1Qkvgw1e7BWhMeQLrtxFowNWDR7W6Bv2M","timestamp":1685165816134}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}